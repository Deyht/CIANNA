{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CIANNA COCO example script**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/CIANNA/blob/CIANNA/examples/COCO/coco_pred_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that does not support FP16 computation, it is advised to change the mixed precision method to FP32C_FP32A in the corresponding cells.\n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIANNA notebook guideline\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COCO prediction network\n",
        "\n",
        "The present notebook uses a network trained on the COCO 2017 training dataset. The training dataset comprises almost 118000 images, each associated with target bounding boxes with 80 possible classes. Python training scripts are provided in the corresponding example directory of CIANNA. The network architecture is similar to a darknet-19 with a few adjustments to account for the current CIANNA capabilities. The network was first pre-trained on ImageNET for classification on 1000 classes at a 224x224 resolution and then further pre-trained at a 448x448 resolution. Finally, the network is trained on the PASCAL dataset for detection at a 416x416 resolution.\n",
        "\n",
        "In this notebook, we apply a trained network to the 5000 images in the COCO 2017 validation dataset, and also provide a simplified script to use this network to perform a detection on an external image.\n",
        "\n"
      ],
      "metadata": {
        "id": "4y-JKSQxfc_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and preparing COCO data"
      ],
      "metadata": {
        "id": "-qkKlvvXRXID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "#Downloading Training and Validation datasets if not already present\n",
        "#datapath is define in aux_fct.py\n",
        "\n",
        "if(not os.path.isdir(data_path+\"annotations\")):\n",
        "\tos.system(\"wget -P %s http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"%(data_path))\n",
        "\tos.system(\"unzip %sannotations_trainval2017.zip\"%(data_path))\n",
        "\tos.system(\"rm %sannotations_trainval2017.zip\"%(data_path))\n",
        "\n",
        "if(not os.path.isdir(data_path+\"val2017\")):\n",
        "\tos.system(\"wget -P %s http://images.cocodataset.org/zips/val2017.zip\"%(data_path))\n",
        "\tos.system(\"unzip %sval2017.zip\"%(data_path))\n",
        "\tos.system(\"rm %sval2017.zip\"%(data_path))\n",
        "\n",
        "\n",
        "data_prefix_list = [\"val2017\"]\n",
        "\n",
        "for data_prefix in data_prefix_list:\n",
        "\n",
        "\twith open(data_path+\"annotations/instances_%s.json\"%(data_prefix), \"r\") as f:\n",
        "\t\tdata = json.load(f)\n",
        "\tprint (data.keys())\n",
        "\n",
        "\tdata_list = {}\n",
        "\n",
        "\tfor item in data[\"images\"]:\n",
        "\t\tdata_list[item[\"id\"]] = item[\"file_name\"]\n",
        "\n",
        "\tkey_id = list(data_list.keys())\n",
        "\tf_file = list(data_list.values())\n",
        "\n",
        "\n",
        "\tfor i in tqdm(range(0, len(key_id))):\n",
        "\n",
        "\t\tim = Image.open(data_path+data_prefix+\"/\"+f_file[i], mode='r')\n",
        "\t\tif(im.format != \"RGB\"):\n",
        "\t\t\tim = im.convert('RGB')\n",
        "\n",
        "\t\tpatch = np.asarray(im)\n",
        "\n",
        "\t\tnp.save(data_path+data_prefix+\"/\"+f_file[i][:-4], patch, allow_pickle=False)\n",
        "\n",
        "\tdata_list = {}\n",
        "\tdata_list2 = {}\n",
        "\tdata_list3 = {}\n",
        "\n",
        "\tfor item in data[\"annotations\"]:\n",
        "\t\tdata_list[item[\"id\"]] = item[\"bbox\"]\n",
        "\t\tdata_list2[item[\"id\"]] = item[\"image_id\"]\n",
        "\t\tdata_list3[item[\"id\"]] = item[\"category_id\"]\n",
        "\n",
        "\tkey_id = list(data_list.keys())\n",
        "\tbbox_list = list(data_list.values())\n",
        "\tim_id_list = list(data_list2.values())\n",
        "\tclass_list = list(data_list3.values())\n",
        "\n",
        "\tfor i in tqdm(range(0, len(key_id))):\n",
        "\t\tf = open(data_path+data_prefix+\"/bbox_%d.txt\"%(im_id_list[i]), \"a\")  # append mode\n",
        "\t\tf.write(\"%f %f %f %f %d\\n\"%(bbox_list[i][0], bbox_list[i][1], max(1.0,bbox_list[i][2]), max(1.0, bbox_list[i][3]), class_list[i]))\n",
        "\t\tf.close()\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "0BNyXejkPEyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing network prediction"
      ],
      "metadata": {
        "id": "JVxa-ehzRgjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "#Comment to access system wide install\n",
        "import sys, glob, os\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "def prep_data(block_id):\n",
        "  print(\"Preparing data for block %d ...\"%(block_id))\n",
        "\n",
        "  l_b_size = min(block_size, nb_val - block_id*block_size)\n",
        "  input_val = np.zeros((l_b_size,flat_image_slice*3), dtype=\"float32\")\n",
        "  targets_val = np.zeros((l_b_size,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "  for i in range(0, min(block_size, nb_val - block_id*block_size)):\n",
        "    i_d = i + block_id*block_size\n",
        "    no_box = 0\n",
        "    patch = np.load(data_path+\"val2017/%s.npy\"%(val_im_path_2017[i_d][:-4]), allow_pickle=False)\n",
        "    val_size[i_d,:] = (np.shape(patch)[:2])\n",
        "\n",
        "    if(os.path.exists(data_path+\"val2017/bbox_%s.txt\"%(val_im_id_2017[i_d]))):\n",
        "      bbox_list = np.loadtxt(data_path+\"val2017/bbox_%s.txt\"%(val_im_id_2017[i_d]))\n",
        "    else:\n",
        "      no_box = 1\n",
        "\n",
        "    if(no_box == 0):\n",
        "      if(bbox_list.ndim == 1):\n",
        "        bbox_list = np.reshape(bbox_list, (1,5))\n",
        "      transformed = transform_val(image=patch, bboxes=bbox_list)\n",
        "      patch_aug = transformed['image']\n",
        "      bbs_aug = np.asarray(transformed['bboxes'])\n",
        "    else:\n",
        "      transformed = transform_val(image=patch, bboxes=[])\n",
        "\n",
        "      patch_aug = transformed['image']\n",
        "      bbs_aug = np.array([])\n",
        "\n",
        "    for depth in range(0,3):\n",
        "      input_val[i,depth*image_size*image_size:(depth+1)*image_size*image_size] = (patch_aug[:,:,depth].flatten(\"C\")-100.0)/155.0\n",
        "\n",
        "    targets_val[i,:] = 0.0\n",
        "    targets_val[i,0] = np.shape(bbs_aug)[0]\n",
        "    if(targets_val[i,0] > max_nb_obj_per_image):\n",
        "      print (\"Max_obj_per_image limit reached: \", int(targets_val[i,0]))\n",
        "      targets_val[i,0] = max_nb_obj_per_image\n",
        "    for k in range(0, int(targets_val[i,0])):\n",
        "\n",
        "      xmin = bbs_aug[k,0]\n",
        "      ymin = bbs_aug[k,1]\n",
        "      xmax = bbs_aug[k,0] + bbs_aug[k,2]\n",
        "      ymax = bbs_aug[k,1] + bbs_aug[k,3]\n",
        "\n",
        "      targets_val[i,1+k*8:1+(k+1)*8] = np.array([np.where(class_id_conv[:] == bbs_aug[k,4])[0][0] + 1,xmin,ymin,0.0,xmax,ymax,1.0,0])\n",
        "\n",
        "  return input_val, targets_val\n",
        "\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "with open(\"classnames.txt\") as f:\n",
        "  class_list = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "class_id_conv = np.arange(1,92)\n",
        "class_id_conv = np.delete(class_id_conv, [11,25,28,29,44,65,67,68,70,82,90])\n",
        "\n",
        "class_list_short = class_list\n",
        "color_offset = 0\n",
        "\n",
        "val_list_2017 = {}\n",
        "with open(data_path+\"annotations/instances_val2017.json\", \"r\") as f:\n",
        "  val2017_instances = json.load(f)\n",
        "for item in val2017_instances[\"images\"]:\n",
        "  val_list_2017[item[\"id\"]] = item[\"file_name\"]\n",
        "\n",
        "val_im_path_2017 = list(val_list_2017.values())\n",
        "val_im_id_2017 = list(val_list_2017.keys())\n",
        "\n",
        "\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 80\n",
        "max_nb_obj_per_image = 70\n",
        "nb_box = 5\n",
        "yolo_reg_size = 32\n",
        "yolo_nb_reg = int(image_size/yolo_reg_size)\n",
        "\n",
        "nb_val = 5000\n",
        "block_size = 2000\n",
        "\n",
        "targets_val = np.zeros((nb_val,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "val_size = np.zeros((nb_val,2), dtype=\"int\")\n",
        "\n",
        "transform_val = A.Compose([\n",
        "    A.LongestMaxSize(max_size=image_size, interpolation=1, p=1.0),\n",
        "    A.PadIfNeeded(min_width=image_size, min_height=image_size, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "  ], bbox_params=A.BboxParams(format='coco'))\n",
        "\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "  load_epoch = int(sys.argv[1])\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=1, b_size=32,\n",
        "  comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", inference_only=1)\n",
        "\n",
        "cnn.set_yolo_params()\n",
        "\n",
        "if(load_epoch > 0):\n",
        "  cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "  if(not os.path.isfile(\"CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\")):\n",
        "    os.system(\"wget https://zenodo.org/records/12801421/files/CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\")\n",
        "  cnn.load(\"CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\", 0, bin=1)\n",
        "\n",
        "#cnn.print_arch_tex(\"./\", \"arch\", activation=1, dropout=0)\n",
        "\n",
        "for block_id in range(0, (nb_val + block_size - 1)//block_size):\n",
        "\n",
        "  b_input_val, b_targets_val = prep_data(block_id)\n",
        "  targets_val[block_id*block_size:(block_id+1)*block_size,:] = b_targets_val[:,:]\n",
        "  cnn.create_dataset(\"TEST\", min(block_size, nb_val - block_id*block_size), b_input_val, b_targets_val)\n",
        "  del(b_input_val, b_targets_val)\n",
        "\n",
        "  cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "  os.system(\"mv fwd_res/net0_%04d.dat fwd_res/net0_%04d_b%d.dat\"%(load_epoch, load_epoch, block_id))\n",
        "  cnn.delete_dataset(\"TEST\")\n",
        "\n",
        "np.save(\"targets_val\",targets_val)\n",
        "np.save(\"val_size\",val_size)\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "IBDYZV_Ef53x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert prediction into the COCO format\n"
      ],
      "metadata": {
        "id": "6KyXAwkGRokK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "#Use auxiliary functions from aux_fct.py\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "with open(\"classnames.txt\") as f:\n",
        "  class_list = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "class_id_conv = np.arange(1,92)\n",
        "class_id_conv = np.delete(class_id_conv, [11,25,28,29,44,65,67,68,70,82,90])\n",
        "\n",
        "class_list_short = class_list\n",
        "color_offset = 0\n",
        "\n",
        "val_list_2017 = {}\n",
        "with open(data_path+\"annotations/instances_val2017.json\", \"r\") as f:\n",
        "  val2017_instances = json.load(f)\n",
        "for item in val2017_instances[\"images\"]:\n",
        "  val_list_2017[item[\"id\"]] = item[\"file_name\"]\n",
        "\n",
        "val_im_path_2017 = list(val_list_2017.values())\n",
        "val_im_id_2017 = list(val_list_2017.keys())\n",
        "\n",
        "\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 80\n",
        "max_nb_obj_per_image = 70\n",
        "nb_box = 5\n",
        "yolo_reg_size = 32\n",
        "yolo_nb_reg = int(image_size/yolo_reg_size)\n",
        "\n",
        "nb_val = 5000\n",
        "block_size = 2000\n",
        "\n",
        "targets_val = np.zeros((nb_val,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "load_epoch = 0\n",
        "obj_threshold = 0.03\n",
        "class_soft_limit = 0.25\n",
        "nms_threshold_same = 0.4\n",
        "nms_threshold_diff = 0.95\n",
        "\n",
        "targets_val = np.load(\"targets_val.npy\")\n",
        "val_size = np.load(\"val_size.npy\")\n",
        "\n",
        "#####################################################\n",
        "# Filter network predictions (objectness, NMS, etc)\n",
        "#####################################################\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "box_list = []\n",
        "\n",
        "for block_id in range(0, (nb_val + block_size - 1)//block_size):\n",
        "\n",
        "  l_b_size = min(block_size, nb_val - block_id*block_size)\n",
        "  pred_raw = np.fromfile(\"fwd_res/net0_%04d_b%d.dat\"%(load_epoch, block_id), dtype=\"float32\")\n",
        "  predict = np.reshape(pred_raw, (l_b_size,nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "  for l in tqdm(range(0, l_b_size)):\n",
        "    i_d = l + block_id*block_size\n",
        "    im_id = val_im_id_2017[i_d]\n",
        "\n",
        "    dim_long = np.argmax(val_size[i_d,:])\n",
        "    ratio = image_size/val_size[i_d,dim_long]\n",
        "\n",
        "    other_dim = int(np.mod(dim_long+1,2))\n",
        "    offset = np.zeros((2))\n",
        "    offset[dim_long] = 0.0\n",
        "    offset[other_dim] = max(0.0,image_size - val_size[i_d,other_dim]*ratio)/2.0\n",
        "\n",
        "    c_tile[:,:] = 0.0\n",
        "    c_tile_kept[:,:] = 0.0\n",
        "\n",
        "    c_pred = predict[l,:,:,:]\n",
        "    c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "    c_nb_box_final = c_nb_box\n",
        "    amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "    c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "\n",
        "    for k in range(0, c_nb_box_final):\n",
        "\n",
        "      x_min  = float(round((c_tile_kept[k,0]-offset[1])/ratio,2))\n",
        "      y_min  = float(round((c_tile_kept[k,1]-offset[0])/ratio,2))\n",
        "      width  = float(round((c_tile_kept[k,2]-offset[1])/ratio - (c_tile_kept[k,0]-offset[1])/ratio,2))\n",
        "      height = float(round((c_tile_kept[k,3]-offset[0])/ratio - (c_tile_kept[k,1]-offset[0])/ratio,2))\n",
        "      cat_id = int(class_id_conv[np.argmax(c_tile_kept[k,7:])])\n",
        "      score  = float(round(c_tile_kept[k,5],4))\n",
        "\n",
        "      box_list.append({\"image_id\": int(im_id), \"category_id\": cat_id,\"bbox\": [x_min,y_min, width,height],\"score\": score})\n",
        "\n",
        "  del (pred_raw, predict)\n",
        "\n",
        "with open(\"fwd_res/pred_%04d.json\"%(load_epoch), \"w\") as f:\n",
        "  json.dump(list(box_list), f)\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "byNOfDIQ4VO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute COCO validation set mAP"
      ],
      "metadata": {
        "id": "Fa5Mvv-V7fLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "git clone https://github.com/cocodataset/cocoapi\n",
        "\n",
        "cd cocoapi/PythonAPI/\n",
        "\n",
        "make"
      ],
      "metadata": {
        "id": "splxr0cp5vJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import sys\n",
        "\n",
        "load_epoch = 0\n",
        "\n",
        "annType = \"bbox\"\n",
        "prefix = \"instances\"\n",
        "\n",
        "dataDir = \"./\"\n",
        "dataType = \"val2017\"\n",
        "annFile = \"%s/annotations/%s_%s.json\"%(dataDir,prefix,dataType)\n",
        "cocoGt = COCO(annFile)\n",
        "\n",
        "resFile=\"fwd_res/pred_%04d.json\"%(load_epoch)\n",
        "cocoDt=cocoGt.loadRes(resFile)\n",
        "\n",
        "imgIds = sorted(cocoGt.getImgIds())\n",
        "imgIds = imgIds[:]\n",
        "\n",
        "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "#cocoEval.params.catIds = [1] #To select class\n",
        "cocoEval.params.imgIds = imgIds\n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ],
      "metadata": {
        "id": "Jt9-zLKl5u9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize network predictions"
      ],
      "metadata": {
        "id": "rjIwV7wcfpCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "#Use auxiliary functions from aux_fct.py\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "with open(\"classnames.txt\") as f:\n",
        "  class_list = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "class_id_conv = np.arange(1,92)\n",
        "class_id_conv = np.delete(class_id_conv, [11,25,28,29,44,65,67,68,70,82,90])\n",
        "\n",
        "class_list_short = class_list\n",
        "color_offset = 0\n",
        "\n",
        "val_list_2017 = {}\n",
        "with open(data_path+\"annotations/instances_val2017.json\", \"r\") as f:\n",
        "  val2017_instances = json.load(f)\n",
        "for item in val2017_instances[\"images\"]:\n",
        "  val_list_2017[item[\"id\"]] = item[\"file_name\"]\n",
        "\n",
        "val_im_path_2017 = list(val_list_2017.values())\n",
        "val_im_id_2017 = list(val_list_2017.keys())\n",
        "\n",
        "\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 80\n",
        "max_nb_obj_per_image = 70\n",
        "nb_box = 5\n",
        "yolo_reg_size = 32\n",
        "yolo_nb_reg = int(image_size/yolo_reg_size)\n",
        "\n",
        "nb_val = 5000\n",
        "block_size = 2000\n",
        "\n",
        "targets_val = np.zeros((nb_val,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "transform_val = A.Compose([\n",
        "    A.LongestMaxSize(max_size=image_size, interpolation=1, p=1.0),\n",
        "    A.PadIfNeeded(min_width=image_size, min_height=image_size, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "  ], bbox_params=A.BboxParams(format='coco'))\n",
        "\n",
        "load_epoch = 0\n",
        "obj_threshold=0.3 #Remove low objectness boxes for display\n",
        "class_soft_limit=0.3\n",
        "nms_threshold_same=0.4\n",
        "nms_threshold_diff=0.95\n",
        "\n",
        "targets_val = np.load(\"targets_val.npy\")\n",
        "val_size = np.load(\"val_size.npy\")\n",
        "\n",
        "#####################################################\n",
        "# Filter network predictions (objectness, NMS, etc)\n",
        "#####################################################\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "for block_id in range(0, (nb_val + block_size - 1)//block_size):\n",
        "\n",
        "  l_b_size = min(block_size, nb_val - block_id*block_size)\n",
        "  pred_raw = np.fromfile(\"fwd_res/net0_%04d_b%d.dat\"%(load_epoch, block_id), dtype=\"float32\")\n",
        "  predict = np.reshape(pred_raw, (l_b_size,nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "  for l in tqdm(range(0, l_b_size)):\n",
        "    i_d = l + block_id*block_size\n",
        "    im_id = val_im_id_2017[i_d]\n",
        "\n",
        "    dim_long = np.argmax(val_size[i_d,:])\n",
        "    ratio = image_size/val_size[i_d,dim_long]\n",
        "\n",
        "    other_dim = int(np.mod(dim_long+1,2))\n",
        "    offset = np.zeros((2))\n",
        "    offset[dim_long] = 0.0\n",
        "    offset[other_dim] = max(0.0,image_size - val_size[i_d,other_dim]*ratio)/2.0\n",
        "\n",
        "    c_tile[:,:] = 0.0\n",
        "    c_tile_kept[:,:] = 0.0\n",
        "\n",
        "    c_pred = predict[l,:,:,:]\n",
        "    c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "    c_nb_box_final = c_nb_box\n",
        "    amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "    c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "\n",
        "    final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "  del (pred_raw, predict)\n",
        "\n",
        "visual_w = 6\n",
        "visual_h = 4\n",
        "display_target=1\n",
        "block_id = 0\n",
        "id_start=0\n",
        "\n",
        "fig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for l in tqdm(range(block_id*block_size + id_start, block_id*block_size + id_start + visual_w*visual_h)):\n",
        "    c_x = (l - id_start - block_id*block_size) // visual_w\n",
        "    c_y = (l - id_start - block_id*block_size) % visual_w\n",
        "\n",
        "    patch = np.load(data_path+\"val2017/%s.npy\"%(val_im_path_2017[l][:-4]), allow_pickle=False)\n",
        "\n",
        "    no_box = 0\n",
        "    if(os.path.exists(data_path+\"val2017/bbox_%s.txt\"%(val_im_id_2017[l]))):\n",
        "      bbox_list = np.loadtxt(data_path+\"val2017/bbox_%s.txt\"%(val_im_id_2017[l]))\n",
        "    else:\n",
        "      no_box = 1\n",
        "\n",
        "    if(no_box == 0):\n",
        "      if(bbox_list.ndim == 1):\n",
        "        bbox_list = np.reshape(bbox_list, (1,5))\n",
        "\n",
        "      transformed = transform_val(image=patch, bboxes=bbox_list)\n",
        "\n",
        "      patch_aug = transformed['image']\n",
        "      bbs_aug = np.asarray(transformed['bboxes'])\n",
        "    else:\n",
        "      transformed = transform_val(image=patch, bboxes=[])\n",
        "\n",
        "      patch_aug = transformed['image']\n",
        "      bbs_aug = np.array([])\n",
        "\n",
        "    ax[c_x,c_y].imshow(patch_aug)\n",
        "    ax[c_x,c_y].axis(\"off\")\n",
        "\n",
        "    im_boxes = final_boxes[l]\n",
        "\n",
        "    if(display_target):\n",
        "      targ_boxes = targets_val[l]\n",
        "      if(targ_boxes[0] == -1):\n",
        "        targ_boxes[0] = 1\n",
        "      for k in range(0, int(targ_boxes[0])):\n",
        "        xmin = targ_boxes[1+k*8+1]\n",
        "        ymin = targ_boxes[1+k*8+2]\n",
        "        xmax = targ_boxes[1+k*8+4]\n",
        "        ymax = targ_boxes[1+k*8+5]\n",
        "        p_c = int(targ_boxes[1+k*8+0]) - 1\n",
        "        diff = int(targ_boxes[1+k*8+7])\n",
        "\n",
        "        el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.4, ls=\"--\", fill=False,\n",
        "          color=plt.cm.tab20((p_c+color_offset)%20), zorder=3)\n",
        "        c_patch = ax[c_x,c_y].add_patch(el)\n",
        "        c_text = ax[c_x,c_y].text(xmin+4, ymin+10, \"%s %d\"%(class_list_short[p_c], (xmax-xmin)*(ymax-ymin)),\n",
        "          c=plt.cm.tab20((p_c+color_offset)%20), fontsize=2, clip_on=True)\n",
        "        c_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground=\"black\"), path_effects.Normal()])\n",
        "        c_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground=\"black\"), path_effects.Normal()])\n",
        "\n",
        "    for k in range(0, np.shape(im_boxes)[0]):\n",
        "\n",
        "      xmin  = float(round((im_boxes[k,0]),2))\n",
        "      ymin  = float(round((im_boxes[k,1]),2))\n",
        "      width  = float(round((im_boxes[k,2]) - (im_boxes[k,0]),2))\n",
        "      height = float(round((im_boxes[k,3]) - (im_boxes[k,1]),2))\n",
        "      p_c = np.argmax(im_boxes[k,7:])\n",
        "      score  = float(round(im_boxes[k,5],4))\n",
        "\n",
        "      el = patches.Rectangle((xmin,ymin), width, height, linewidth=0.4, fill=False, color=plt.cm.tab20((p_c+color_offset)%20), zorder=3)\n",
        "      c_patch = ax[c_x,c_y].add_patch(el)\n",
        "      c_text = ax[c_x,c_y].text(xmin+5, ymin+height-4, \"%s:%d-%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,6],im_boxes[k,5],np.max(im_boxes[k,7:])),\n",
        "        c=plt.cm.tab20((p_c+color_offset)%20), fontsize=2,clip_on=True)\n",
        "      c_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground=\"black\"), path_effects.Normal()])\n",
        "      c_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground=\"black\"), path_effects.Normal()])\n",
        "\n",
        "plt.savefig(\"pred_mosaic.jpg\",dpi=500, bbox_inches='tight')\n",
        "\n",
        "EOF\n",
        "\n"
      ],
      "metadata": {
        "id": "6T4R1ymsLwas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "#Display the produced JPG\n",
        "from IPython.display import Image\n",
        "Image(\"pred_mosaic.jpg\", width=1280)"
      ],
      "metadata": {
        "id": "9Khtu34PTWPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External image prediction\n",
        "\n",
        "Minimalist example on how to use the network to perform prediction on an external .jpg image."
      ],
      "metadata": {
        "id": "DGDbKbtNZE4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib import patches\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from numba import jit\n",
        "\n",
        "#Comment to access system wide install\n",
        "import sys, glob, os\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "#Minimum deployement setup for prediction on a single image\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def fct_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]) + 1)\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]) + 1)\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0] + 1)*abs(box1[3] - box1[1] + 1) + \\\n",
        "\t\tabs(box2[2]-box2[0] + 1)*abs(box2[3] - box2[1] + 1) - inter_2d\n",
        "\tenclose_w = (max(box1[2], box2[2]) - min(box1[0], box2[0]))\n",
        "\tenclose_h = (max(box1[3], box2[3]) - min(box1[1],box2[1]))\n",
        "\tenclose_2d = enclose_w*enclose_h\n",
        "\n",
        "\tcx_a = (box1[2] + box1[0])*0.5; cx_b = (box2[2] + box2[0])*0.5\n",
        "\tcy_a = (box1[3] + box1[1])*0.5; cy_b = (box2[3] + box2[1])*0.5\n",
        "\tdist_cent = np.sqrt((cx_a - cx_b)*(cx_a - cx_b) + (cy_a - cy_b)*(cy_a - cy_b))\n",
        "\tdiag_enclose = np.sqrt(enclose_w*enclose_w + enclose_h*enclose_h)\n",
        "\n",
        "  # DIoU\n",
        "\treturn float(inter_2d)/float(uni_2d) - float(dist_cent)/float(diag_enclose)\n",
        "  # GIoU\n",
        "\t#return float(inter_2d)/float(uni_2d) - float(enclose_2d - uni_2d)/float(enclose_2d)\n",
        "\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit):\n",
        "\tc_nb_box = 0\n",
        "\tfor i in range(0,yolo_nb_reg):\n",
        "\t\tfor j in range(0,yolo_nb_reg):\n",
        "\t\t\tfor k in range(0,nb_box):\n",
        "\t\t\t\toffset = int(k*(8+nb_class)) #no +1 for box prior in prediction\n",
        "\t\t\t\tc_box[4] = c_pred[offset+6,i,j]\n",
        "\t\t\t\tc_box[5] = c_pred[offset+7,i,j]\n",
        "\t\t\t\tp_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "\t\t\t\tcl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "\n",
        "\t\t\t\tif(c_box[5] >= obj_threshold and c_box[5]*p_c**1 >= 0.01 and p_c > class_soft_limit):\n",
        "\t\t\t\t\tc_box[0] = c_pred[offset,i,j]\n",
        "\t\t\t\t\tc_box[1] = c_pred[offset+1,i,j]\n",
        "\t\t\t\t\tc_box[2] = c_pred[offset+3,i,j]\n",
        "\t\t\t\t\tc_box[3] = c_pred[offset+4,i,j]\n",
        "\n",
        "\t\t\t\t\tc_box[6] = k\n",
        "\t\t\t\t\tc_box[7:] = c_pred[offset+8:offset+8+nb_class,i,j]\n",
        "\t\t\t\t\tc_tile[c_nb_box,:] = c_box[:]\n",
        "\t\t\t\t\tc_nb_box +=1\n",
        "\n",
        "\treturn c_nb_box\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff):\n",
        "  c_nb_box_final = 0\n",
        "  c_box_size_prev = c_nb_box\n",
        "\n",
        "  while(c_nb_box > 0):\n",
        "    max_objct = np.argmax(c_tile[:c_box_size_prev,5]*amax_array[:c_box_size_prev])\n",
        "    c_box = np.copy(c_tile[max_objct])\n",
        "    c_tile[max_objct,5] = 0.0\n",
        "    c_tile_kept[c_nb_box_final] = c_box\n",
        "    c_nb_box_final += 1\n",
        "    c_nb_box -= 1\n",
        "    i = 0\n",
        "\n",
        "    for i in range(0,c_box_size_prev):\n",
        "      if(c_tile[i,5] < 0.00000001):\n",
        "        continue\n",
        "      IoU = fct_IoU(c_box[:4], c_tile[i,:4])\n",
        "\n",
        "      if((IoU > nms_threshold_same and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]))\n",
        "      \tor (IoU > nms_threshold_diff and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]))):\n",
        "        c_tile[i] = 0.0\n",
        "        c_nb_box -= 1\n",
        "\n",
        "  return c_nb_box_final\n",
        "\n",
        "\n",
        "#The network is resiliant to slight augment in image resolution, which increase the mAP\n",
        "#We recommand changing image_size by step of 64 (2 grid elements)\n",
        "#Here training resolution was 416\n",
        "\n",
        "image_size = 416 + 64*3\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_box = 5\n",
        "nb_class = 80\n",
        "\n",
        "color_offset = 0\n",
        "\n",
        "max_nb_obj_per_image = 70\n",
        "\n",
        "yolo_nb_reg = int(image_size/32)\n",
        "c_size = 32\n",
        "\n",
        "with open(\"classnames.txt\") as f:\n",
        "    class_list = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "class_id_conv = np.arange(1,92)\n",
        "class_id_conv = np.delete(class_id_conv, [11,25,28,29,44,65,67,68,70,82,90])\n",
        "\n",
        "\n",
        "if(not os.path.isfile(\"office_1.jpg\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/GynmcyDtkrsbyLe/download/office_1.jpg\")\n",
        "\n",
        "im = Image.open(\"office_1.jpg\", mode='r')\n",
        "\n",
        "if(im.format != \"RGB\"):\n",
        "\tim = im.convert('RGB')\n",
        "\n",
        "patch = np.asarray(im)\n",
        "\n",
        "dim_long = np.argmax(im.size)\n",
        "ratio = image_size/im.size[dim_long]\n",
        "\n",
        "other_dim = int(np.mod(dim_long+1,2))\n",
        "offset = np.zeros((2))\n",
        "offset[dim_long] = 0.0\n",
        "offset[other_dim] = max(0.0,image_size - im.size[other_dim]*ratio)/2.0\n",
        "\n",
        "transform = A.Compose([\n",
        "\tA.LongestMaxSize(max_size=image_size, interpolation=1, p=1.0),\n",
        "\tA.PadIfNeeded(min_width=image_size, min_height=image_size, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "])\n",
        "\n",
        "transformed = transform(image=patch)\n",
        "patch_aug = transformed['image']\n",
        "\n",
        "input_data = f_ar(np.zeros((1,3*image_size*image_size)))\n",
        "empty_target = f_ar(np.zeros((1,1)))\n",
        "\n",
        "for depth in range(0,3):\n",
        "\tinput_data[0,depth*flat_image_slice:(depth+1)*flat_image_slice] = (patch_aug[:,:,depth].flatten(\"C\") - 100.0)/155.0\n",
        "\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=1, b_size=1,\n",
        "\tcomp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", inference_only=1)\n",
        "\n",
        "cnn.create_dataset(\"TEST\", 1, input_data, empty_target)\n",
        "\n",
        "cnn.set_yolo_params()\n",
        "\n",
        "load_epoch = 0\n",
        "if(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "\tif(not os.path.isfile(\"CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\")):\n",
        "\t\tos.system(\"wget https://zenodo.org/records/12801421/files/CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\")\n",
        "\tcnn.load(\"CIANNA_net_model_coco_v1.0_darknet19custom_res416_map50_39.9_fp16.dat\", 0, bin=1)\n",
        "\n",
        "#cnn.print_arch_tex(\"./\", \"arch\", activation=1, dropout=0)\n",
        "\n",
        "cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (1, nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "#Choice of filters that produce visually appealing results (!= best mAP )\n",
        "obj_threshold = 0.45\n",
        "class_soft_limit = 0.3\n",
        "nms_threshold_same = 0.4\n",
        "nms_threshold_diff = 0.9\n",
        "\n",
        "\n",
        "c_tile[:,:] = 0.0\n",
        "c_tile_kept[:,:] = 0.0\n",
        "\n",
        "c_pred = predict[0,:,:,:]\n",
        "c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "c_nb_box_final = c_nb_box\n",
        "amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "\n",
        "#Image is displayed at full resolution. Changing imshow and removing ratio allows to visualize the prediction at the resolution seen by the network.\n",
        "fig, ax = plt.subplots(1,1, figsize=(4,4), dpi=200, constrained_layout=True)\n",
        "\n",
        "ax.imshow(patch)\n",
        "ax.axis('off')\n",
        "\n",
        "im_boxes = final_boxes[0]\n",
        "\n",
        "for k in range(0, np.shape(im_boxes)[0]):\n",
        "\txmin = max(0.0,(im_boxes[k,0]-offset[0])/ratio)\n",
        "\tymin = max(0.0,(im_boxes[k,1]-offset[1])/ratio)\n",
        "\txmax = min(im.size[0],(im_boxes[k,2]-offset[0])/ratio)\n",
        "\tymax = min(im.size[1],(im_boxes[k,3]-offset[1])/ratio)\n",
        "\n",
        "\tp_c = np.argmax(im_boxes[k,7:])\n",
        "\n",
        "\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.4, fill=False, color=plt.cm.tab20((p_c+color_offset)%20), zorder=3)\n",
        "\tc_patch = ax.add_patch(el)\n",
        "\tc_text = ax.text(xmin+8, ymax-15, \"%s:%d-%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,6],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20((p_c+color_offset)%20), fontsize=2,clip_on=True)\n",
        "\tc_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\tc_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "plt.savefig(\"pred_on_image.jpg\",dpi=400, bbox_inches='tight')\n",
        "\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "aqEZNkQnZSS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/COCO/\n",
        "\n",
        "#Display the produced JPG\n",
        "from IPython.display import Image\n",
        "Image(\"pred_on_image.jpg\", width=960)"
      ],
      "metadata": {
        "id": "KAfN6Vo7UU__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}