{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CIANNA ImageNET example script**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/CIANNA/blob/CIANNA/examples/ImageNET/imagenet_pred_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that supports high FP16 compute scaling (e.g the Tesla T4), it is advised to change the mixed_precision parameter in the last cell to \"FP16C_FP32A\".  \n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIANNA notebook guideline\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageNET 2012 prediction network\n",
        "\n",
        "The present notebook uses a network trained on the ImageNET 2012 dataset.\n",
        "The training dataset comprises 1.28 million examples, each associated with a single target class in a list of 1000 possible classes. Due to the dataset size, providing a training notebook compatible with the Free version of Colab is strongly impractical. Still, Python training scripts are provided in the corresponding example directory of CIANNA.\n",
        "\n",
        "In this notebook, we apply a pre-trained network to the 50000 validation set of ImageNET 2012, and also provide a simplified script to use this network to perform a prediction on an external image. The network architecture is similar to a darknet-19 with a few adjustments to account for the current CIANNA capabilities. The network was first trained at a 224x224 resolution and then further trained at a 448x448 resolution. Network save files are provided for both resolutions. To reduce data download and pre-processing, we provide a test dataset in an already processed binary format containing a subset of 10000 validation images in a squared and centered 500x500 resolution.\n",
        "\n"
      ],
      "metadata": {
        "id": "4y-JKSQxfc_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/ImageNET/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import os, glob\n",
        "\n",
        "#Comment to access system wide install\n",
        "import sys, glob\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "if(not os.path.isdir(\"ImageNET_aux_data\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/Pqbn4cC2azo84Z2/download/ImageNET_aux_data.tar.gz\")\n",
        "\tos.system(\"tar -xvzf ImageNET_aux_data.tar.gz\")\n",
        "\n",
        "if(not os.path.isfile(\"ImageNET_val10k_bin.tar.gz\")):\n",
        "  os.system(\"wget https://share.obspm.fr/s/qG9TMDHXWNxr2Qx/download/ImageNET_val10k_bin.tar.gz\")\n",
        "  os.system(\"tar -xvzf ImageNET_val10k_bin.tar.gz\")\n",
        "\n",
        "processed_data_path = \"./val\"\n",
        "\n",
        "image_size_val = 480\n",
        "image_size = 448\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 1000\n",
        "total_val = 10000\n",
        "nb_keep_val = 2000\n",
        "load_epoch = 0\n",
        "\n",
        "transform_val = A.Compose([\n",
        "\tA.SmallestMaxSize(max_size=image_size_val, interpolation=1, p=1.0),\n",
        "\tA.CenterCrop(width=image_size, height=image_size, p=1.0),\n",
        "])\n",
        "\n",
        "val_list = np.loadtxt(\"ImageNET_aux_data/imagenet_2012_1000classes_val.txt\", dtype=\"str\")\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class, bias=0.1,\n",
        "\t b_size=16, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", adv_size=35)\n",
        "#Change to FP32 if the allocated GPU does not support FP16 compute\n",
        "\n",
        "targets_zero = np.zeros((nb_class), dtype=\"float32\")\n",
        "input_val = np.zeros((nb_keep_val,flat_image_slice*3), dtype=\"float32\")\n",
        "targets_val = np.zeros((nb_keep_val,nb_class), dtype=\"float32\")\n",
        "\n",
        "if(load_epoch > 0):\n",
        "    cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch, load_epoch, bin=1)\n",
        "else:\n",
        "  #Not trained as a resolution agnostic network\n",
        "  if(image_size == 224):\n",
        "    if(not os.path.isfile(\"ImageNET_aux_data/net_pretrain_medium_224_acc70.dat\")):\n",
        "      os.system(\"wget -P ImageNET_aux_data/ https://share.obspm.fr/s/dj69Fm5Gyaenzjw/download/net_pretrain_medium_224_acc70.dat\")\n",
        "    cnn.load(\"ImageNET_aux_data/net_pretrain_medium_224_acc70.dat\", 0, bin=1)\n",
        "  elif(image_size == 448):\n",
        "    if(not os.path.isfile(\"ImageNET_aux_data/net_pretrain_medium_448_acc74.dat\")):\n",
        "      os.system(\"wget -P ImageNET_aux_data/ https://share.obspm.fr/s/PJaJ6an7amZiQBC/download/net_pretrain_medium_448_acc74.dat\")\n",
        "    cnn.load(\"ImageNET_aux_data/net_pretrain_medium_448_acc74.dat\", 0, bin=1)\n",
        "  else:\n",
        "    print(\"No trained network for the define image resolution\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "for block in range(int(total_val/nb_keep_val)):\n",
        "  print(\"Loading validation dataset block %d\"%(block))\n",
        "  for i in range(0, nb_keep_val):\n",
        "    patch = np.load(processed_data_path+\"/valid_img_%04d.npy\"%(i+int(block*nb_keep_val)), allow_pickle=False)\n",
        "\n",
        "    transformed = transform_val(image=patch)\n",
        "    patch_aug = transformed['image']\n",
        "\n",
        "    for depth in range(0,3):\n",
        "      input_val[i,depth*flat_image_slice:(depth+1)*flat_image_slice] = (patch_aug[:,:,depth].flatten(\"C\") - 100.0)/155.0\n",
        "\n",
        "    targets_val[i,:] = np.copy(targets_zero[:])\n",
        "    targets_val[i,int(val_list[i+int(block*nb_keep_val),1])] = 1.0\n",
        "\n",
        "  cnn.create_dataset(\"TEST\", nb_keep_val, input_val[:,:], targets_val[:,:])\n",
        "\n",
        "  cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "  cnn.delete_dataset(\"TEST\")\n",
        "\n",
        "  os.system(\"mv fwd_res/net0_%04d.dat fwd_res/net0_%04d_b%d.dat\"%(load_epoch, load_epoch, block))\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "IBDYZV_Ef53x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the TOP-1 and TOP-5 errors\n",
        "\n",
        "%cd /content/CIANNA/examples/ImageNET/\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "total_val = 10000\n",
        "nb_keep_val = 2000\n",
        "nb_class = 1000\n",
        "load_epoch = 0\n",
        "\n",
        "val_list = np.loadtxt(\"ImageNET_aux_data/imagenet_2012_1000classes_val.txt\", dtype=\"str\")\n",
        "\n",
        "for top_error in [1,5]:\n",
        "\n",
        "  count = 0\n",
        "  count_max = 0\n",
        "\n",
        "  for block in range(int(total_val/nb_keep_val)):\n",
        "    pred_raw = np.fromfile(\"fwd_res/net0_%04d_b%d.dat\"%(load_epoch, block), dtype=\"float32\")\n",
        "    predict = np.reshape(pred_raw, (nb_keep_val,nb_class))\n",
        "\n",
        "    for i in range(0, nb_keep_val):\n",
        "      ind = np.argpartition(predict[i], -top_error)[-top_error:]\n",
        "      count_max += np.max(predict[i])\n",
        "\n",
        "      if(np.isin(int(val_list[i+block*nb_keep_val,1]), ind[:])):\n",
        "        count += 1\n",
        "\n",
        "  print (\"Top-%d error\"%(top_error))\n",
        "  print (1.0 - count/(total_val))\n",
        "  print (\"Avg max class value\")\n",
        "  print (count_max/(total_val))"
      ],
      "metadata": {
        "id": "6CREUJBcLpTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External image prediction\n",
        "\n",
        "Minimalist example on how to use the network to perform prediction on an external .jpg image."
      ],
      "metadata": {
        "id": "DGDbKbtNZE4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/ImageNET/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "import albumentations as A\n",
        "import os, cv2\n",
        "from PIL import Image\n",
        "\n",
        "#Comment to access system wide install\n",
        "import sys, glob\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "#Minimum deployement setup for prediction on a single image\n",
        "\n",
        "image_size_val = 480\n",
        "image_size = 448\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 1000\n",
        "\n",
        "class_list = np.loadtxt(\"ImageNET_aux_data/imagenet_2012_class_list.txt\", dtype=\"str\")[:,1]\n",
        "\n",
        "if(not os.path.isfile(\"ImageNET_aux_data/office_1.jpg\")):\n",
        "\tos.system(\"wget -P ImageNET_aux_data/ https://share.obspm.fr/s/GynmcyDtkrsbyLe/download/office_1.jpg\")\n",
        "\n",
        "im = Image.open(\"ImageNET_aux_data/office_1.jpg\", mode='r')\n",
        "\n",
        "if(im.format != \"RGB\"):\n",
        "\tim = im.convert('RGB')\n",
        "\n",
        "patch = np.asarray(im)\n",
        "\n",
        "transform = A.Compose([\n",
        "\tA.SmallestMaxSize(max_size=image_size_val, interpolation=1, p=1.0),\n",
        "\tA.PadIfNeeded(min_width=image_size_val, min_height=image_size_val, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "\tA.CenterCrop(width=image_size, height=image_size, p=1.0),\n",
        "])\n",
        "\n",
        "transformed = transform(image=patch)\n",
        "patch_aug = transformed['image']\n",
        "\n",
        "input_data = f_ar(np.zeros((1,3*image_size*image_size)))\n",
        "empty_target = f_ar(np.zeros((1,1000)))\n",
        "\n",
        "for depth in range(0,3):\n",
        "\tinput_data[0,depth*flat_image_slice:(depth+1)*flat_image_slice] = (patch_aug[:,:,depth].flatten(\"C\") - 100.0)/155.0\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "\tload_epoch = int(sys.argv[1])\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class, bias=0.1,\n",
        "\t b_size=1, comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", adv_size=35)\n",
        "\n",
        "cnn.create_dataset(\"TEST\", 1, input_data, empty_target)\n",
        "\n",
        "if(load_epoch > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_epoch, load_epoch, bin=1)\n",
        "else:\n",
        "\t#Not trained as a resolution agnostic network\n",
        "\tif(image_size == 224):\n",
        "\t\tif(not os.path.isfile(\"ImageNET_aux_data/net_pretrain_medium_224_acc70.dat\")):\n",
        "\t\t\tos.system(\"wget -P ImageNET_aux_data/ https://share.obspm.fr/s/dj69Fm5Gyaenzjw/download/net_pretrain_medium_224_acc70.dat\")\n",
        "\t\tcnn.load(\"ImageNET_aux_data/net_pretrain_medium_224_acc70.dat\", 0, bin=1)\n",
        "\telif(image_size == 448):\n",
        "\t\tif(not os.path.isfile(\"ImageNET_aux_data/net_pretrain_medium_448_acc74.dat\")):\n",
        "\t\t\tos.system(\"wget -P ImageNET_aux_data/ https://share.obspm.fr/s/PJaJ6an7amZiQBC/download/net_pretrain_medium_448_acc74.dat\")\n",
        "\t\tcnn.load(\"ImageNET_aux_data/net_pretrain_medium_448_acc74.dat\", 0, bin=1)\n",
        "\telse:\n",
        "\t\tprint(\"No trained network for the define image resolution\")\n",
        "\t\texit()\n",
        "\n",
        "cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "top_error = 5\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%(load_epoch), dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (1,nb_class))\n",
        "\n",
        "ind_best = np.argpartition(predict[0], -top_error)[-top_error:]\n",
        "ind_sort = ind_best[np.argsort(predict[0, ind_best])][::-1]\n",
        "pred_values = predict[0, ind_sort]\n",
        "\n",
        "print(\"Top %d predictions\"%(top_error))\n",
        "for k in range(0, top_error):\n",
        "  print(\"%0.2f - %s\"%(pred_values[k], class_list[ind_sort[k]]))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, dpi=200, constrained_layout=True)\n",
        "\n",
        "ax.imshow(patch)\n",
        "ax.axis('off')\n",
        "\n",
        "for k in range(0, top_error):\n",
        "\tc_text = ax.text(0.02, 1.0-0.04-k*0.04, \"%0.2f - %s\"%(pred_values[k], class_list[ind_sort[k]]),\n",
        "\t\tc=plt.cm.tab20(ind_sort[k]%20), fontsize=6, clip_on=True, transform=ax.transAxes)\n",
        "\tc_text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'), path_effects.Normal()])\n",
        "\n",
        "plt.savefig(\"pred_on_image.jpg\", dpi=200)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "aqEZNkQnZSS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the produced JPG\n",
        "from IPython.display import Image\n",
        "Image(\"pred_on_image.jpg\", width=960)"
      ],
      "metadata": {
        "id": "vggx8BwVZwpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
