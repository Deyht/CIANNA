{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CIANNA PASCAL example script**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/CIANNA/blob/CIANNA/examples/PASCAL/pascal_pred_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that does not support FP16 computation, it is advised to change the mixed precision method to FP32C_FP32A in the corresponding cells.\n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIANNA notebook guideline\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASCAL-VOC prediction network\n",
        "\n",
        "The present notebook uses a network trained on the PASCAL 2012 trainval and and PASCAL 2007 trainval datasets. The training dataset comprises 16551 images, each associated with target bounding boxes with 20 possible classes. Python training scripts are provided in the corresponding example directory of CIANNA. The network architecture is similar to a darknet-19 with a few adjustments to account for the current CIANNA capabilities. The network was first pre-trained on ImageNET for classification on 1000 classes at a 224x224 resolution and then further pre-trained at a 448x448 resolution. Finally, the network is trained on the PASCAL dataset for detection at a 416x416 resolution.\n",
        "\n",
        "In this notebook, we apply a trained network to the 4952 images in the PASCAL 2007 test dataset, and also provide a simplified script to use this network to perform a detection on an external image. Before prediction, all the test images are re-processed to be square-padded and centered at a 480x480 resolution.\n",
        "\n"
      ],
      "metadata": {
        "id": "4y-JKSQxfc_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and preparing PASCAL data"
      ],
      "metadata": {
        "id": "-qkKlvvXRXID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "def make_square(im, min_size, fill_color=(0, 0, 0, 0)):\n",
        "  x, y = im.size\n",
        "  size = max(min_size, x, y)\n",
        "  new_im = Image.new('RGB', (size, size), fill_color)\n",
        "  new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "  return new_im\n",
        "\n",
        "if(not os.path.isdir(data_path+\"VOCdevkit\")):\n",
        "  os.system(\"wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\")\n",
        "  os.system(\"tar -xf VOCtest_06-Nov-2007.tar\")\n",
        "\n",
        "test_list_2007  = np.loadtxt(data_path+\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\"    , dtype=\"str\")\n",
        "\n",
        "nb_test_2007 = 4952\n",
        "nb_keep_val = 4952\n",
        "block_size = 2000\n",
        "image_size_raw = 480\n",
        "nb_class = 20\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  all_im = np.zeros((min(block_size, nb_keep_val - block_id*block_size), image_size_raw, image_size_raw, 3), dtype=\"uint8\")\n",
        "  all_im_prop = np.zeros((min(block_size, nb_keep_val - block_id*block_size), 4), dtype=\"float32\")\n",
        "\n",
        "  for i in tqdm(range(0, min(block_size, nb_keep_val - block_id*block_size))):\n",
        "    im = Image.open(data_path+\"VOCdevkit/VOC2007/JPEGImages/\"+test_list_2007[block_id*block_size + i]+\".jpg\")\n",
        "\n",
        "    width, height = im.size\n",
        "\n",
        "    im = make_square(im, image_size_raw)\n",
        "    width2, height2 = im.size\n",
        "\n",
        "    x_offset = int((width2 - width)*0.5)\n",
        "    y_offset = int((height2 - height)*0.5)\n",
        "\n",
        "    all_im_prop[i] = [x_offset, y_offset, width2, height2]\n",
        "\n",
        "    im = im.resize((image_size_raw,image_size_raw), resample=Image.BILINEAR)\n",
        "    im_array = np.asarray(im)\n",
        "    for depth in range(0,3):\n",
        "      all_im[i,:,:,depth] = im_array[:,:,depth]\n",
        "\n",
        "  all_im.tofile(\"all_im_b%d.dat\"%(block_id))\n",
        "  all_im_prop.tofile(\"all_im_prop_b%d.dat\"%(block_id))\n",
        "\n",
        "  del (all_im, all_im_prop)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "0BNyXejkPEyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing network prediction"
      ],
      "metadata": {
        "id": "JVxa-ehzRgjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "#Comment to access system wide install\n",
        "import sys, glob, os\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "def prep_data(block_id):\n",
        "  print(\"Preparing data for block %d ...\"%(block_id))\n",
        "\n",
        "  l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "  input_val = np.zeros((l_b_size,flat_image_slice*3), dtype=\"float32\")\n",
        "  targets_val = np.zeros((l_b_size,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "  all_im = np.fromfile(data_path+\"all_im_b%d.dat\"%(block_id), dtype=\"uint8\")\n",
        "  all_im_prop = np.fromfile(data_path+\"all_im_prop_b%d.dat\"%(block_id), dtype=\"float32\")\n",
        "  all_im = np.reshape(all_im, ((l_b_size, image_size_raw, image_size_raw, 3)))\n",
        "  all_im_prop = np.reshape(all_im_prop,(l_b_size, 4))\n",
        "\n",
        "  for i in range(0, min(block_size, nb_keep_val - block_id*block_size)):\n",
        "\n",
        "    tree = ET.parse(data_path+\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[block_id*block_size + i]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    obj_list = root.findall(\"object\", namespaces=None)\n",
        "\n",
        "    patch = np.copy(all_im[i])\n",
        "    x_offset, y_offset, width, height = all_im_prop[i]\n",
        "    max_dim = max(width, height)\n",
        "\n",
        "    bbox_list = np.zeros((len(obj_list),7))\n",
        "    k = 0\n",
        "    for obj in obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "      int_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "      xmin = (float(bndbox.find(\"xmin\").text)+x_offset)*image_size_raw/width\n",
        "      ymin = (float(bndbox.find(\"ymin\").text)+y_offset)*image_size_raw/height\n",
        "      xmax = (float(bndbox.find(\"xmax\").text)+x_offset)*image_size_raw/width\n",
        "      ymax = (float(bndbox.find(\"ymax\").text)+y_offset)*image_size_raw/height\n",
        "\n",
        "      bbox_list[k,:] = np.array([xmin,ymin,xmax,ymax,int_class,0,k])\n",
        "      if(diff.text != \"1\"):\n",
        "        class_count_val[int_class] += 1\n",
        "      else:\n",
        "        bbox_list[k,5] = 1\n",
        "      k += 1\n",
        "\n",
        "    bbs = bbox_list[:,:]\n",
        "    transformed = transform_val(image=patch,bboxes=bbs)\n",
        "    patch_aug = transformed['image']\n",
        "    bbs_aug = np.asarray(transformed['bboxes'])\n",
        "\n",
        "    for depth in range(0,3):\n",
        "      input_val[i,depth*flat_image_slice:(depth+1)*flat_image_slice] = (patch_aug[:,:,depth].flatten(\"C\")-100.0)/155.0\n",
        "\n",
        "    targets_val[i,:] = 0.0\n",
        "    targets_val[i,0] = np.shape(bbs_aug)[0]\n",
        "    for k in range(0, np.shape(bbs_aug)[0]):\n",
        "      xmin = bbs_aug[k,0]\n",
        "      ymin = bbs_aug[k,1]\n",
        "      xmax = bbs_aug[k,2]\n",
        "      ymax = bbs_aug[k,3]\n",
        "      orig_box = bbox_list[int(bbs_aug[k,6])]\n",
        "      diff = bbs_aug[k,5]\n",
        "      targets_val[i,1+k*8:1+(k+1)*8] = np.array([bbs_aug[k,4]+1,xmin,ymin,0.0,xmax,ymax,1.0,diff])\n",
        "\n",
        "    if(targets_val[i,0] > max_nb_obj_per_image):\n",
        "      targets_val[i,0] = max_nb_obj_per_image\n",
        "\n",
        "  del(all_im, all_im_prop)\n",
        "  return input_val, targets_val\n",
        "\n",
        "\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"], dtype=\"str\")\n",
        "\n",
        "test_list_2007 = np.loadtxt(data_path+\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "image_size_raw = 480\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 20\n",
        "max_nb_obj_per_image = 56\n",
        "\n",
        "nb_test_2007 = 4952\n",
        "nb_keep_val = 4952\n",
        "block_size = 2000\n",
        "\n",
        "transform_val = A.Compose([\n",
        "  A.Resize(width=image_size,height=image_size,interpolation=1)\n",
        "  ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "class_count_val = np.zeros((nb_class))\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "  load_epoch = int(sys.argv[1])\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=1, b_size=32,\n",
        "  comp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", inference_only=1)\n",
        "\n",
        "cnn.set_yolo_params()\n",
        "\n",
        "if(load_epoch > 0):\n",
        "  cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch,load_epoch, bin=1)\n",
        "else:\n",
        "  if(not os.path.isfile(\"net_train_pascal_416_fp16_75.3map.dat\")):\n",
        "    os.system(\"wget https://share.obspm.fr/s/XxY3gXnpXgsxA24/download/net_train_pascal_416_fp16_75.3map.dat\")\n",
        "  cnn.load(\"net_train_pascal_416_fp16_75.3map.dat\", 0, bin=1)\n",
        "\n",
        "#cnn.print_arch_tex(\"./\", \"arch\", activation=1, dropout=0)\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  input_val, targets_val = prep_data(block_id)\n",
        "  cnn.create_dataset(\"TEST\", min(block_size, nb_keep_val - block_id*block_size), input_val, targets_val)\n",
        "  del(input_val, targets_val)\n",
        "\n",
        "  cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "  os.system(\"mv fwd_res/net0_%04d.dat fwd_res/net0_%04d_b%d.dat\"%(load_epoch, load_epoch, block_id))\n",
        "  cnn.delete_dataset(\"TEST\")\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "IBDYZV_Ef53x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute PASCAL 2007 testset mAP"
      ],
      "metadata": {
        "id": "6KyXAwkGRokK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "#Use auxiliary functions from aux_fct.py\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"], dtype=\"str\")\n",
        "\n",
        "test_list_2007 = np.loadtxt(data_path+\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "image_size_raw = 480\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 20\n",
        "max_nb_obj_per_image = 56\n",
        "\n",
        "nb_test_2007 = 4952\n",
        "nb_keep_val = 4952\n",
        "block_size = 2000\n",
        "\n",
        "load_epoch = 0\n",
        "obj_threshold=0.03\n",
        "class_soft_limit=0.3\n",
        "nms_threshold_same=0.4\n",
        "nms_threshold_diff=0.95\n",
        "\n",
        "transform_val = A.Compose([\n",
        "  A.Resize(width=image_size,height=image_size,interpolation=1)\n",
        "  ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "#####################################################\n",
        "# Construct validation target\n",
        "#####################################################\n",
        "\n",
        "class_count_val = np.zeros((nb_class))\n",
        "\n",
        "def prep_data_targ(block_id):\n",
        "  print(\"Preparing data for block %d ...\"%(block_id))\n",
        "\n",
        "  l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "  targets_val = np.zeros((l_b_size,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "  all_im = np.fromfile(data_path+\"all_im_b%d.dat\"%(block_id), dtype=\"uint8\")\n",
        "  all_im_prop = np.fromfile(data_path+\"all_im_prop_b%d.dat\"%(block_id), dtype=\"float32\")\n",
        "  all_im = np.reshape(all_im, ((l_b_size, image_size_raw, image_size_raw, 3)))\n",
        "  all_im_prop = np.reshape(all_im_prop,(l_b_size, 4))\n",
        "\n",
        "  for i in range(0, min(block_size, nb_keep_val - block_id*block_size)):\n",
        "\n",
        "    tree = ET.parse(data_path+\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[block_id*block_size + i]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    obj_list = root.findall(\"object\", namespaces=None)\n",
        "\n",
        "    patch = np.copy(all_im[i])\n",
        "    x_offset, y_offset, width, height = all_im_prop[i]\n",
        "    max_dim = max(width, height)\n",
        "\n",
        "    bbox_list = np.zeros((len(obj_list),7))\n",
        "    k = 0\n",
        "    for obj in obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "      int_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "      xmin = (float(bndbox.find(\"xmin\").text)+x_offset)*image_size_raw/width\n",
        "      ymin = (float(bndbox.find(\"ymin\").text)+y_offset)*image_size_raw/height\n",
        "      xmax = (float(bndbox.find(\"xmax\").text)+x_offset)*image_size_raw/width\n",
        "      ymax = (float(bndbox.find(\"ymax\").text)+y_offset)*image_size_raw/height\n",
        "\n",
        "      bbox_list[k,:] = np.array([xmin,ymin,xmax,ymax,int_class,0,k])\n",
        "      if(diff.text != \"1\"):\n",
        "        class_count_val[int_class] += 1\n",
        "      else:\n",
        "        bbox_list[k,5] = 1\n",
        "      k += 1\n",
        "\n",
        "    bbs = bbox_list[:,:]\n",
        "    transformed = transform_val(image=patch,bboxes=bbs)\n",
        "    patch_aug = transformed['image']\n",
        "    bbs_aug = np.asarray(transformed['bboxes'])\n",
        "\n",
        "    targets_val[i,:] = 0.0\n",
        "    targets_val[i,0] = np.shape(bbs_aug)[0]\n",
        "    for k in range(0, np.shape(bbs_aug)[0]):\n",
        "      xmin = bbs_aug[k,0]\n",
        "      ymin = bbs_aug[k,1]\n",
        "      xmax = bbs_aug[k,2]\n",
        "      ymax = bbs_aug[k,3]\n",
        "      orig_box = bbox_list[int(bbs_aug[k,6])]\n",
        "      diff = bbs_aug[k,5]\n",
        "      targets_val[i,1+k*8:1+(k+1)*8] = np.array([bbs_aug[k,4]+1,xmin,ymin,0.0,xmax,ymax,1.0,diff])\n",
        "\n",
        "    if(targets_val[i,0] > max_nb_obj_per_image):\n",
        "      targets_val[i,0] = max_nb_obj_per_image\n",
        "\n",
        "  del(all_im, all_im_prop)\n",
        "  return targets_val\n",
        "\n",
        "targets_val = np.zeros((nb_keep_val,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  b_targets_val = prep_data_targ(block_id)\n",
        "  targets_val[block_id*block_size:(block_id+1)*block_size,:] = b_targets_val[:,:]\n",
        "  del (b_targets_val)\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# Filter network predictions (objectness, NMS, etc)\n",
        "#####################################################\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "  pred_raw = np.fromfile(\"fwd_res/net0_%04d_b%d.dat\"%(load_epoch, block_id), dtype=\"float32\")\n",
        "  predict = np.reshape(pred_raw, (l_b_size,nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "  for l in tqdm(range(0, l_b_size)):\n",
        "\n",
        "    c_tile[:,:] = 0.0\n",
        "    c_tile_kept[:,:] = 0.0\n",
        "\n",
        "    c_pred = predict[l,:,:,:]\n",
        "    c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "    c_nb_box_final = c_nb_box\n",
        "    amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "    c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "\n",
        "    final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# Compute the mAP for the validation sample\n",
        "#####################################################\n",
        "\n",
        "AP_IoU_val=0.5\n",
        "\n",
        "for l in range(0,nb_keep_val):\n",
        "  p_c = np.amax(final_boxes[l][:,7:], axis=1)\n",
        "  final_boxes[l] = (final_boxes[l][(final_boxes[l][:,5]*p_c[:]**1).argsort()])[::-1]\n",
        "\n",
        "recall_precision = np.empty((nb_keep_val), dtype=\"object\")\n",
        "\n",
        "print(\"Find associations ...\", flush=True)\n",
        "\n",
        "for i_d in range(0, nb_keep_val):\n",
        "\n",
        "  recall_precision[i_d] = np.zeros((np.shape(final_boxes[i_d])[0], 6))\n",
        "\n",
        "  if(np.shape(final_boxes[i_d])[0] == 0):\n",
        "    continue\n",
        "\n",
        "  recall_precision[i_d][:,0] = np.amax(final_boxes[i_d][:,7:], axis=1)\n",
        "  recall_precision[i_d][:,1] = final_boxes[i_d][:,5]\n",
        "\n",
        "  recall_precision[i_d][:,5] = np.argmax(final_boxes[i_d][:,7:], axis=1)\n",
        "\n",
        "  kept_boxes = targets_val[i_d]\n",
        "  kept_mask = np.zeros(int(kept_boxes[0]), dtype=\"int\")\n",
        "\n",
        "  for i in range(0,np.shape(final_boxes[i_d])[0]):\n",
        "    best_IoU = -2.0\n",
        "    best_targ = -1\n",
        "    for j in range(0,int(kept_boxes[0])):\n",
        "      xmin = (kept_boxes[1+j*8+1])\n",
        "      ymin = (kept_boxes[1+j*8+2])\n",
        "      xmax = (kept_boxes[1+j*8+4])\n",
        "      ymax = (kept_boxes[1+j*8+5])\n",
        "      c_kept_box = np.array([xmin, ymin, xmax, ymax])\n",
        "      c_IoU = fct_classical_IoU(c_kept_box, final_boxes[i_d][i,:4])\n",
        "      if(c_IoU > best_IoU and np.argmax(final_boxes[i_d][i,7:]) == int(kept_boxes[1+j*8+0]-1) and kept_mask[j] == 0):\n",
        "        best_IoU = c_IoU\n",
        "        best_targ = j\n",
        "\n",
        "    if (best_IoU >= AP_IoU_val):\n",
        "      if(kept_boxes[1+best_targ*8+7] > 0.99):\n",
        "        recall_precision[i_d][i,2] = -1\n",
        "      else:\n",
        "        recall_precision[i_d][i,2] = 1\n",
        "        recall_precision[i_d][i,3] = best_targ\n",
        "        recall_precision[i_d][i,4] = c_IoU\n",
        "        kept_mask[best_targ] = 1\n",
        "\n",
        "\n",
        "print(\"Process and flatten the mAP result\")\n",
        "flatten = np.vstack(recall_precision.flatten())\n",
        "\n",
        "recall_precision_f = np.zeros((np.shape(flatten)[0], 10))\n",
        "recall_precision_f[:,:6] = flatten[:,:]\n",
        "\n",
        "recall_precision_fs = (recall_precision_f[(recall_precision_f[:,1]*recall_precision_f[:,0]**1).argsort()])[::-1]\n",
        "\n",
        "ignore_index = np.where(recall_precision_fs[:,2] == -1)[0]\n",
        "\n",
        "recall_precision_fs = np.delete(recall_precision_fs,ignore_index, axis=0)\n",
        "\n",
        "recall_precision_fs[:,6] = np.cumsum(recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,7] = np.cumsum(1.0 - recall_precision_fs[:,2])\n",
        "recall_precision_fs[:,8] = recall_precision_fs[:,6] / (recall_precision_fs[:,6]+recall_precision_fs[:,7])\n",
        "recall_precision_fs[:,9] = recall_precision_fs[:,6] / np.sum(class_count_val)\n",
        "\n",
        "interp_curve = np.maximum.accumulate(recall_precision_fs[::-1,8])[::-1]\n",
        "\n",
        "AP_all = np.trapz(interp_curve, recall_precision_fs[:,9])\n",
        "print (\"AP_all (%.2f): %f%%\"%(AP_IoU_val, AP_all*100.0))\n",
        "\n",
        "plt.figure(figsize=(4*1.0,3*1.0), dpi=200, constrained_layout=True)\n",
        "plt.plot(recall_precision_fs[:,9], recall_precision_fs[:,8])\n",
        "plt.plot(recall_precision_fs[:,9], interp_curve, label=\"New\")\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "plt.title(\"All classes as one AP curve\", fontsize=8)\n",
        "\n",
        "sumAP = 0\n",
        "print (\"**** Per class AP ****\")\n",
        "fig, ax = plt.subplots(figsize=(4*1.3,3*1.3), dpi=200, constrained_layout=True)\n",
        "plt.xlabel(r\"Recall\")\n",
        "plt.ylabel(r\"Precision\")\n",
        "\n",
        "for k in range(0, nb_class):\n",
        "  index = np.where(recall_precision_fs[:,5] == k)\n",
        "  l_recall_precision_fs = recall_precision_fs[index[0]]\n",
        "\n",
        "  l_recall_precision_fs[:,6] = np.cumsum(l_recall_precision_fs[:,2])\n",
        "  l_recall_precision_fs[:,7] = np.cumsum(1.0 - l_recall_precision_fs[:,2])\n",
        "  l_recall_precision_fs[:,8] = l_recall_precision_fs[:,6] / (l_recall_precision_fs[:,6]+l_recall_precision_fs[:,7])\n",
        "  l_recall_precision_fs[:,9] = l_recall_precision_fs[:,6] / class_count_val[k]\n",
        "\n",
        "  interp_curve = np.maximum.accumulate(l_recall_precision_fs[::-1,8])[::-1]\n",
        "\n",
        "  AP = np.trapz(interp_curve, l_recall_precision_fs[:,9])\n",
        "  sumAP += AP\n",
        "\n",
        "  plt.plot(l_recall_precision_fs[:,9], interp_curve, label=class_list[k],c=plt.cm.tab20(k))\n",
        "\n",
        "  print(\"AP %-15s: %5.2f%%   Total: %4d - T: %4d - F: %4d\"%(class_list[k], AP*100.0, class_count_val[k], l_recall_precision_fs[-1,6], l_recall_precision_fs[-1,7]))\n",
        "\n",
        "print (\"\\n**** mAP (%.2f): %f%% ****\"%(AP_IoU_val, sumAP/nb_class*100.0))\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.02,0.98), fontsize=8)\n",
        "plt.title(\"Per class AP curve\", fontsize=8)\n",
        "plt.savefig(\"AP_curve_@%.2f_per_class.jpg\"%(AP_IoU_val))\n",
        "\n",
        "del (targets_val, final_boxes)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "byNOfDIQ4VO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize network predictions"
      ],
      "metadata": {
        "id": "rjIwV7wcfpCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "#Use auxiliary functions from aux_fct.py\n",
        "\n",
        "data_path = \"./\"\n",
        "\n",
        "class_list = np.array([\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "\t\t\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\\\n",
        "\t\t\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"], dtype=\"str\")\n",
        "\n",
        "test_list_2007 = np.loadtxt(data_path+\"VOCdevkit/VOC2007/ImageSets/Main/test.txt\", dtype=\"str\")\n",
        "\n",
        "image_size_raw = 480\n",
        "image_size = 416\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 20\n",
        "max_nb_obj_per_image = 56\n",
        "\n",
        "transform_val = A.Compose([\n",
        "  A.Resize(width=image_size,height=image_size,interpolation=1)\n",
        "  ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "nb_test_2007 = 4952\n",
        "nb_keep_val = 4952\n",
        "block_size = 2000\n",
        "\n",
        "load_epoch = 0\n",
        "obj_threshold=0.3 #Remove low objectness boxes for display\n",
        "class_soft_limit=0.3\n",
        "nms_threshold_same=0.4\n",
        "nms_threshold_diff=0.95\n",
        "\n",
        "#####################################################\n",
        "# Construct validation target\n",
        "#####################################################\n",
        "\n",
        "class_count_val = np.zeros((nb_class))\n",
        "\n",
        "def prep_data_targ(block_id):\n",
        "  print(\"Preparing data for block %d ...\"%(block_id))\n",
        "\n",
        "  l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "  targets_val = np.zeros((l_b_size,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "  all_im = np.fromfile(data_path+\"all_im_b%d.dat\"%(block_id), dtype=\"uint8\")\n",
        "  all_im_prop = np.fromfile(data_path+\"all_im_prop_b%d.dat\"%(block_id), dtype=\"float32\")\n",
        "  all_im = np.reshape(all_im, ((l_b_size, image_size_raw, image_size_raw, 3)))\n",
        "  all_im_prop = np.reshape(all_im_prop,(l_b_size, 4))\n",
        "\n",
        "  for i in range(0, min(block_size, nb_keep_val - block_id*block_size)):\n",
        "\n",
        "    tree = ET.parse(data_path+\"VOCdevkit/VOC2007/Annotations/\"+test_list_2007[block_id*block_size + i]+\".xml\")\n",
        "    root = tree.getroot()\n",
        "    obj_list = root.findall(\"object\", namespaces=None)\n",
        "\n",
        "    patch = np.copy(all_im[i])\n",
        "    x_offset, y_offset, width, height = all_im_prop[i]\n",
        "    max_dim = max(width, height)\n",
        "\n",
        "    bbox_list = np.zeros((len(obj_list),7))\n",
        "    k = 0\n",
        "    for obj in obj_list:\n",
        "      diff = obj.find(\"difficult\", namespaces=None)\n",
        "      oclass = obj.find(\"name\", namespaces=None)\n",
        "      bndbox = obj.find(\"bndbox\", namespaces=None)\n",
        "\n",
        "      int_class = int(np.where(class_list[:] == oclass.text)[0])\n",
        "      xmin = (float(bndbox.find(\"xmin\").text)+x_offset)*image_size_raw/width\n",
        "      ymin = (float(bndbox.find(\"ymin\").text)+y_offset)*image_size_raw/height\n",
        "      xmax = (float(bndbox.find(\"xmax\").text)+x_offset)*image_size_raw/width\n",
        "      ymax = (float(bndbox.find(\"ymax\").text)+y_offset)*image_size_raw/height\n",
        "\n",
        "      bbox_list[k,:] = np.array([xmin,ymin,xmax,ymax,int_class,0,k])\n",
        "      if(diff.text != \"1\"):\n",
        "        class_count_val[int_class] += 1\n",
        "      else:\n",
        "        bbox_list[k,5] = 1\n",
        "      k += 1\n",
        "\n",
        "    bbs = bbox_list[:,:]\n",
        "    transformed = transform_val(image=patch,bboxes=bbs)\n",
        "    patch_aug = transformed['image']\n",
        "    bbs_aug = np.asarray(transformed['bboxes'])\n",
        "\n",
        "    targets_val[i,:] = 0.0\n",
        "    targets_val[i,0] = np.shape(bbs_aug)[0]\n",
        "    for k in range(0, np.shape(bbs_aug)[0]):\n",
        "      xmin = bbs_aug[k,0]\n",
        "      ymin = bbs_aug[k,1]\n",
        "      xmax = bbs_aug[k,2]\n",
        "      ymax = bbs_aug[k,3]\n",
        "      orig_box = bbox_list[int(bbs_aug[k,6])]\n",
        "      diff = bbs_aug[k,5]\n",
        "      targets_val[i,1+k*8:1+(k+1)*8] = np.array([bbs_aug[k,4]+1,xmin,ymin,0.0,xmax,ymax,1.0,diff])\n",
        "\n",
        "    if(targets_val[i,0] > max_nb_obj_per_image):\n",
        "      targets_val[i,0] = max_nb_obj_per_image\n",
        "\n",
        "  del(all_im, all_im_prop)\n",
        "  return targets_val\n",
        "\n",
        "targets_val = np.zeros((nb_keep_val,1+max_nb_obj_per_image*(7+1)), dtype=\"float32\")\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  b_targets_val = prep_data_targ(block_id)\n",
        "  targets_val[block_id*block_size:(block_id+1)*block_size,:] = b_targets_val[:,:]\n",
        "  del (b_targets_val)\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# Filter network predictions (objectness, NMS, etc)\n",
        "#####################################################\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "for block_id in range(0, (nb_keep_val + block_size - 1)//block_size):\n",
        "\n",
        "  l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "  pred_raw = np.fromfile(\"fwd_res/net0_%04d_b%d.dat\"%(load_epoch, block_id), dtype=\"float32\")\n",
        "  predict = np.reshape(pred_raw, (l_b_size,nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "  for l in tqdm(range(0, l_b_size)):\n",
        "\n",
        "    c_tile[:,:] = 0.0\n",
        "    c_tile_kept[:,:] = 0.0\n",
        "\n",
        "    c_pred = predict[l,:,:,:]\n",
        "    c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "    c_nb_box_final = c_nb_box\n",
        "    amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "    c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "\n",
        "    final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "\n",
        "visual_w = 6\n",
        "visual_h = 4\n",
        "display_target=1\n",
        "block_id = 0\n",
        "id_start=0\n",
        "\n",
        "l_b_size = min(block_size, nb_keep_val - block_id*block_size)\n",
        "all_im = np.fromfile(data_path+\"all_im_b%d.dat\"%(block_id), dtype=\"uint8\")\n",
        "all_im_prop = np.fromfile(data_path+\"all_im_prop_b%d.dat\"%(block_id), dtype=\"float32\")\n",
        "all_im = np.reshape(all_im, ((l_b_size, image_size_raw, image_size_raw, 3)))\n",
        "all_im_prop = np.reshape(all_im_prop,(l_b_size, 4))\n",
        "\n",
        "fig, ax = plt.subplots(visual_h, visual_w, figsize=(1.5*visual_w,1.5*visual_h), dpi=210, constrained_layout=True)\n",
        "\n",
        "for i in range(0, visual_h):\n",
        "  for j in range(0, visual_w):\n",
        "    i_d = block_id*block_size + i*visual_w + j + id_start\n",
        "\n",
        "    c_data = all_im[i_d]/255.0\n",
        "    ax[i,j].imshow(c_data)\n",
        "    ax[i,j].axis('off')\n",
        "\n",
        "    im_boxes = final_boxes[i_d]\n",
        "\n",
        "    if(display_target):\n",
        "      targ_boxes = targets_val[i_d]\n",
        "      for k in range(0, int(targ_boxes[0])):\n",
        "        xmin = targ_boxes[1+k*8+1] *(image_size_raw/image_size)\n",
        "        ymin = targ_boxes[1+k*8+2] *(image_size_raw/image_size)\n",
        "        xmax = targ_boxes[1+k*8+4] *(image_size_raw/image_size)\n",
        "        ymax = targ_boxes[1+k*8+5] *(image_size_raw/image_size)\n",
        "        p_c = int(targ_boxes[1+k*8+0]) - 1\n",
        "\n",
        "        el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.4, ls=\"--\", fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "        c_patch = ax[i,j].add_patch(el)\n",
        "        c_text  = ax[i,j].text(xmin+4, ymin+10, \"%s\"%(class_list[p_c]), c=plt.cm.tab20(p_c), fontsize=2, clip_on=True)\n",
        "        c_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'), path_effects.Normal()])\n",
        "        c_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'), path_effects.Normal()])\n",
        "\n",
        "\n",
        "    for k in range(0, np.shape(im_boxes)[0]):\n",
        "      xmin = max(-0.5,(im_boxes[k,0])*(image_size_raw/image_size) - 0.5)\n",
        "      ymin = max(-0.5,(im_boxes[k,1])*(image_size_raw/image_size) - 0.5)\n",
        "      xmax = min(image_size_raw-0.5,(im_boxes[k,2])*(image_size_raw/image_size) - 0.5)\n",
        "      ymax = min(image_size_raw-0.5,(im_boxes[k,3])*(image_size_raw/image_size) - 0.5)\n",
        "\n",
        "      p_c = np.argmax(im_boxes[k,7:])\n",
        "\n",
        "      el = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.4, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "      c_patch = ax[i,j].add_patch(el)\n",
        "      c_text = ax[i,j].text(xmin+5, ymax-4, \"%s:%d-%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,6],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=2,clip_on=True)\n",
        "      c_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "                        path_effects.Normal()])\n",
        "      c_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "                        path_effects.Normal()])\n",
        "\n",
        "plt.savefig(\"pred_mosaic.jpg\",dpi=500, bbox_inches='tight')\n",
        "\n",
        "del (targets_val, all_im, all_im_prop)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "xAHpEk7YfrgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "#Display the produced JPG\n",
        "from IPython.display import Image\n",
        "Image(\"pred_mosaic.jpg\", width=1280)"
      ],
      "metadata": {
        "id": "X6WLH0IMTLL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External image prediction\n",
        "\n",
        "Minimalist example on how to use the network to perform prediction on an external .jpg image."
      ],
      "metadata": {
        "id": "DGDbKbtNZE4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "import matplotlib.patheffects as path_effects\n",
        "from PIL import Image\n",
        "\n",
        "from numba import jit\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "#Comment to access system wide install\n",
        "import os, sys, glob\n",
        "sys.path.insert(0,glob.glob('../../src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "#Minimum deployement setup for prediction on a single image\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def fct_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]) + 1)\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]) + 1)\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0] + 1)*abs(box1[3] - box1[1] + 1) + \\\n",
        "\t\tabs(box2[2]-box2[0] + 1)*abs(box2[3] - box2[1] + 1) - inter_2d\n",
        "\tenclose_w = (max(box1[2], box2[2]) - min(box1[0], box2[0]))\n",
        "\tenclose_h = (max(box1[3], box2[3]) - min(box1[1],box2[1]))\n",
        "\tenclose_2d = enclose_w*enclose_h\n",
        "\n",
        "\tcx_a = (box1[2] + box1[0])*0.5; cx_b = (box2[2] + box2[0])*0.5\n",
        "\tcy_a = (box1[3] + box1[1])*0.5; cy_b = (box2[3] + box2[1])*0.5\n",
        "\tdist_cent = np.sqrt((cx_a - cx_b)*(cx_a - cx_b) + (cy_a - cy_b)*(cy_a - cy_b))\n",
        "\tdiag_enclose = np.sqrt(enclose_w*enclose_w + enclose_h*enclose_h)\n",
        "\n",
        "  # DIoU\n",
        "\treturn float(inter_2d)/float(uni_2d) - float(dist_cent)/float(diag_enclose)\n",
        "  # GIoU\n",
        "\t#return float(inter_2d)/float(uni_2d) - float(enclose_2d - uni_2d)/float(enclose_2d)\n",
        "\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def fct_classical_IoU(box1, box2):\n",
        "\tinter_w = max(0, min(box1[2], box2[2]) - max(box1[0], box2[0]) + 1)\n",
        "\tinter_h = max(0, min(box1[3], box2[3]) - max(box1[1], box2[1]) + 1)\n",
        "\tinter_2d = inter_w*inter_h\n",
        "\tuni_2d = abs(box1[2]-box1[0] + 1)*abs(box1[3] - box1[1] + 1) + \\\n",
        "\t\tabs(box2[2]-box2[0] + 1)*abs(box2[3] - box2[1] + 1) - inter_2d\n",
        "\n",
        "\treturn float(inter_2d)/float(uni_2d)\n",
        "\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit):\n",
        "\tc_nb_box = 0\n",
        "\tfor i in range(0,yolo_nb_reg):\n",
        "\t\tfor j in range(0,yolo_nb_reg):\n",
        "\t\t\tfor k in range(0,nb_box):\n",
        "\t\t\t\toffset = int(k*(8+nb_class)) #no +1 for box prior in prediction\n",
        "\t\t\t\tc_box[4] = c_pred[offset+6,i,j]\n",
        "\t\t\t\tc_box[5] = c_pred[offset+7,i,j]\n",
        "\t\t\t\tp_c = np.max(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "\t\t\t\tcl = np.argmax(c_pred[offset+8:offset+8+nb_class,i,j])\n",
        "\n",
        "\t\t\t\tif(c_box[5] >= obj_threshold and c_box[5]*p_c**1 >= 0.01 and p_c > class_soft_limit):\n",
        "\t\t\t\t\tc_box[0] = c_pred[offset,i,j]\n",
        "\t\t\t\t\tc_box[1] = c_pred[offset+1,i,j]\n",
        "\t\t\t\t\tc_box[2] = c_pred[offset+3,i,j]\n",
        "\t\t\t\t\tc_box[3] = c_pred[offset+4,i,j]\n",
        "\n",
        "\t\t\t\t\tc_box[6] = k\n",
        "\t\t\t\t\tc_box[7:] = c_pred[offset+8:offset+8+nb_class,i,j]\n",
        "\t\t\t\t\tc_tile[c_nb_box,:] = c_box[:]\n",
        "\t\t\t\t\tc_nb_box +=1\n",
        "\n",
        "\treturn c_nb_box\n",
        "\n",
        "\n",
        "@jit(nopython=True, cache=False, fastmath=False)\n",
        "def apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff):\n",
        "\tc_nb_box_final = 0\n",
        "\tc_box_size_prev = c_nb_box\n",
        "\n",
        "\twhile(c_nb_box > 0):\n",
        "\t\tmax_objct = np.argmax(c_tile[:c_box_size_prev,5]*amax_array[:c_box_size_prev])\n",
        "\t\tc_box = np.copy(c_tile[max_objct])\n",
        "\t\tc_tile[max_objct,5] = 0.0\n",
        "\t\tc_tile_kept[c_nb_box_final] = c_box\n",
        "\t\tc_nb_box_final += 1\n",
        "\t\tc_nb_box -= 1\n",
        "\t\ti = 0\n",
        "\n",
        "\t\tfor i in range(0,c_box_size_prev):\n",
        "\t\t\tif(c_tile[i,5] < 0.00000001):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tIoU = fct_IoU(c_box[:4], c_tile[i,:4])\n",
        "\n",
        "\t\t\tif((IoU > nms_threshold_same and np.argmax(c_box[7:]) == np.argmax(c_tile[i,7:]))\n",
        "\t\t\t\tor (IoU > nms_threshold_diff and np.argmax(c_box[7:]) != np.argmax(c_tile[i,7:]))):\n",
        "\t\t\t\tc_tile[i] = 0.0\n",
        "\t\t\t\tc_nb_box -= 1\n",
        "\n",
        "\treturn c_nb_box_final\n",
        "\n",
        "\n",
        "\n",
        "class_list = np.array([\"aeroplane\", \"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\\\n",
        "    \"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\", \"motorbike\",\\\n",
        "    \"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\",\"background\"])\n",
        "\n",
        "#The network is resiliant to slight augment in image resolution, which increase the mAP\n",
        "#We recommand changing image_size by step of 64 (2 grid elements)\n",
        "#Here training resolution was 416\n",
        "\n",
        "image_size = 416 + 64*1\n",
        "flat_image_slice = image_size*image_size\n",
        "nb_class = 20\n",
        "nb_box = 5\n",
        "yolo_reg_size = 32\n",
        "yolo_nb_reg = int(image_size/yolo_reg_size)\n",
        "\n",
        "load_epoch = 0\n",
        "\n",
        "\n",
        "if(not os.path.isfile(\"office_1.jpg\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/GynmcyDtkrsbyLe/download/office_1.jpg\")\n",
        "\n",
        "im = Image.open(\"office_1.jpg\", mode='r')\n",
        "\n",
        "if(im.format != \"RGB\"):\n",
        "\tim = im.convert('RGB')\n",
        "\n",
        "patch = np.asarray(im)\n",
        "\n",
        "dim_long = np.argmax(im.size)\n",
        "ratio = image_size/im.size[dim_long]\n",
        "\n",
        "other_dim = int(np.mod(dim_long+1,2))\n",
        "offset = np.zeros((2))\n",
        "offset[dim_long] = 0.0\n",
        "offset[other_dim] = max(0.0,image_size - im.size[other_dim]*ratio)/2.0\n",
        "\n",
        "transform = A.Compose([\n",
        "\tA.LongestMaxSize(max_size=image_size, interpolation=1, p=1.0),\n",
        "\tA.PadIfNeeded(min_width=image_size, min_height=image_size, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "])\n",
        "\n",
        "transformed = transform(image=patch)\n",
        "patch_aug = transformed['image']\n",
        "\n",
        "input_data = f_ar(np.zeros((1,3*image_size*image_size)))\n",
        "empty_target = f_ar(np.zeros((1,1)))\n",
        "\n",
        "for depth in range(0,3):\n",
        "\tinput_data[0,depth*flat_image_slice:(depth+1)*flat_image_slice] = (patch_aug[:,:,depth].flatten(\"C\") - 100.0)/155.0\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=1, b_size=1,\n",
        "\tcomp_meth='C_CUDA', dynamic_load=1, mixed_precision=\"FP16C_FP32A\", inference_only=1)\n",
        "\n",
        "cnn.create_dataset(\"TEST\", 1, input_data, empty_target)\n",
        "\n",
        "cnn.set_yolo_params()\n",
        "\n",
        "cnn.load(\"net_train_pascal_416_fp16_75.3map.dat\",0, bin=1)\n",
        "\n",
        "cnn.print_arch_tex(\"./\", \"arch\", activation=1, dropout=0)\n",
        "\n",
        "cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "\n",
        "\n",
        "obj_threshold=0.3\n",
        "class_soft_limit=0.3\n",
        "nms_threshold_same=0.3\n",
        "nms_threshold_diff=0.95\n",
        "\n",
        "pred_raw = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_epoch, dtype=\"float32\")\n",
        "predict = np.reshape(pred_raw, (1, nb_box*(8+nb_class),yolo_nb_reg,yolo_nb_reg))\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_class)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_class),dtype=\"float32\")\n",
        "\n",
        "final_boxes = []\n",
        "\n",
        "c_tile[:,:] = 0.0\n",
        "c_tile_kept[:,:] = 0.0\n",
        "\n",
        "c_pred = predict[0,:,:,:]\n",
        "c_nb_box = box_extraction(c_pred, c_box, c_tile, obj_threshold, class_soft_limit)\n",
        "\n",
        "c_nb_box_final = c_nb_box\n",
        "amax_array = np.amax(c_tile[:,7:], axis=1)\n",
        "c_nb_box_final = apply_NMS(c_tile, c_tile_kept, c_box, c_nb_box, amax_array, nms_threshold_same, nms_threshold_diff)\n",
        "\n",
        "final_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "\n",
        "#Image is displayed at full resolution. Changing imshow and removing ratio allows to visualize the prediction at the resolution seen by the network.\n",
        "fig, ax = plt.subplots(1,1, dpi=210, constrained_layout=True)\n",
        "\n",
        "ax.imshow(patch)\n",
        "ax.axis('off')\n",
        "\n",
        "im_boxes = final_boxes[0]\n",
        "\n",
        "for k in range(0, np.shape(im_boxes)[0]):\n",
        "\txmin = (im_boxes[k,0]-offset[0])/ratio\n",
        "\tymin = (im_boxes[k,1]-offset[1])/ratio\n",
        "\txmax = (im_boxes[k,2]-offset[0])/ratio\n",
        "\tymax = (im_boxes[k,3]-offset[1])/ratio\n",
        "\n",
        "\tp_c = np.argmax(im_boxes[k,7:])\n",
        "\n",
        "\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.4, fill=False, color=plt.cm.tab20(p_c), zorder=3)\n",
        "\tc_patch = ax.add_patch(el)\n",
        "\tc_text = ax.text(xmin+5, ymax-4, \"%s:%d-%0.2f-%0.2f\"%(class_list[p_c],im_boxes[k,6],im_boxes[k,5],np.max(im_boxes[k,7:])), c=plt.cm.tab20(p_c), fontsize=2,clip_on=True)\n",
        "\tc_patch.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\tc_text.set_path_effects([path_effects.Stroke(linewidth=0.8, foreground='black'),\n",
        "\t\t\t\t\t\t\t\t\t\tpath_effects.Normal()])\n",
        "\n",
        "plt.savefig(\"pred_on_image.jpg\",dpi=400, bbox_inches='tight')\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "aqEZNkQnZSS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/PASCAL/\n",
        "\n",
        "#Display the produced JPG\n",
        "from IPython.display import Image\n",
        "Image(\"pred_on_image.jpg\", width=960)"
      ],
      "metadata": {
        "id": "KAfN6Vo7UU__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}